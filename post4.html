<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VITA - Desenvolvimento do OCR para Paragens</title>
    <link rel="icon" type="icon" href="Images/vita logo.png">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <h1>VITA - Visually Impaired Transit Assistant</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="blogposts.html">Blog</a></li>
                <li><a href="team.html">Team</a></li>
            </ul>
        </nav>

        <div class="theme-toggle">
            <button id="theme-switch" aria-label="Toggle dark mode">
                <svg class="sun-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
                    <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 3v1m0 16v1m-9-9H4m16 0h-1m-7 7a6 6 0 110-12 6 6 0 010 12z"></path>
                </svg>
                <svg class="moon-icon" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
                    <path fill="none" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"></path>
                </svg>
            </button>
        </div>

    </header>
    <main>
        <article>
            <article class="post">
                <h2>O Desenvolvimento do OCR para Paragens de Autocarros</h2>
                <p><em>11/06/2025 - Post feito por Alexandre Escudeiro</em></p>

                <h3>Prótotipo inicial com OpenCV e TesseractOCR</h3>
                <p>
                    A jornada de desenvolvimento do algoritmo de reconhecimento de caracteres dos letreiros dos autocarros começou em Abril deste mesmo ano, com uma pesquisa profunda sobre as ferramentas disponíveis online para nos ajudarem a solucionar o nosso problema.
                </p>
                <p>
                    Após essa pesquisa decidimos utilizar dois softwares “open-source” chamados OpenCV e Tesseract OCR.
                </p>
                <p>
                    Assim, arrancámos com um pequeno teste a uma imagem de um sinal de STOP e com acesso ao comando <code>cv2.imread()</code>. Utilizamos a função de leitura estática desta mesma imagem, de seguida aplicamos um pré-processamento simples, com conversão da imagem para cinzento e um filtro com threshold adaptativo, de forma a melhorar a definição da imagem. Por fim, aplicámos o comando <code>pytesseract.image_to_string</code> para extrair o texto bruto da imagem.
                </p>
                <p>
                    Embora os resultados tenham sido bons em imagens muito controladas, rapidamente percebemos que iríamos ter de implementar uma solução muito mais complexa do que a que tínhamos. Encontrámos ruído, ângulos inclinados e placas parcialmente visíveis, que nos levaram a ter uma taxa de sucesso de cerca de 50% das imagens.
                </p>

                    <h2>EasyOCR e Filtros</h2>
                <p>
                    Para aumentar a robustez do programa integrámos outro algoritmo de OCR chamado EasyOCR para tirar partido de reconhecimento de texto em layouts mais complexos, sendo que este algoritmo já vem pré-treinado para encontrar texto em ângulos mais difíceis ou imagens com menor resolução.
                </p>
                <p>
                    Aplicámos também filtros morfológicos e de nitidez através do comando <code>cv2.filter2D</code> para reduzir o ruído de fundo, mas estes filtros exigiam calibragem individual para cada uma das imagens que queríamos ler.
                </p>
                <p>
                    E, por fim, introduzimos um filtro de confiança para ler apenas imagens com um nível de confiança superior a 60%, para descartar fragmentos sem importância. Assim conseguimos aumentar a nossa taxa de sucesso para cerca de 60% das imagens lidas.
                </p>

                <figure>
                    <img src="Images\img1post2alex.jpg" alt="Teste com EasyOCR" style="display: block; margin: auto;"/>
                    <figcaption>TESTE COM EASY_OCR</figcaption>
                </figure>

                <h3>Transição para YOLOv8 e OCR Híbrido</h3>
                <p>
                    Perante a persistente dificuldade em aplicar o OCR à região de interesse (ROI) correta testámos uma abordagem diferente da anterior: a de utilizar um modelo de reconhecimento de imagens treinado com ajuda de “machine learning” através de uma ferramenta da Ultralytics. Treinámos o nosso algoritmo para detetar rapidamente a posição dos letreiros dos autocarros de maneira a podermos fazer posteriormente o crop dessa zona dos letreiros e aplicar o OCR apenas a essa zona e assim eliminar a maior parte do ruído que encontrávamos.
                </p>
                <p>
                    Assim, conseguimos filtrar rapidamente todos os frames que não estavam na nossa “ROI” e fazer com que só os crops importantes passem pelo OCR, passando assim a processar cerca de 3 frames por segundo no RaspberryPi e com uma precisão de leitura de cerca de 90%.
                </p>

                <figure>
                    <img src="Images\img2post2alex.png" alt="Resultados do modelo de treino dos autocarros" style="display: block; margin: auto;" />
                    <figcaption>RESULTADOS MODELO DE TREINO DOS AUTOCARROS</figcaption>
                </figure>

                <h3>Correção com GTFS</h3>
                <p>
                    Com acesso aos ficheiros GTFS das operadoras locais, neste caso Carris e Carris Metropolitana, disponíveis online, tivemos acesso a toda a informação sobre as carreiras, os seus horários e as paragens disponíveis na área metropolitana de Lisboa.
                </p>
                <p>
                    Carregámos ambos os ficheiros num DataFrame único com todas as rotas e viagens, de seguida expandimos os destinos do tipo A – B em A e B, de forma a ficar com linhas do género Número + Direção para cada sentido das carreiras.
                </p>
                <p>
                    Implementámos ainda um “fuzzy-match”, uma ferramenta que faz uma comparação entre dados, que aplicámos ao texto que resulta do processamento do OCR e tentámos encontrar uma correspondência nos ficheiros GTFS. Para obter um menor tempo de busca adicionámos um passo extra em que é pedido ao técnico que está a instalar para fornecer o ID correspondente à paragem onde está, limitando o algoritmo a procurar apenas carreiras que estão previstas para essa mesma paragem.
                </p>
                <p>
                    Sempre que a similaridade exceda 0.6 (ou seja 60%), substituímos o texto bruto do OCR pela versão do GTFS, garantindo assim consistência nos resultados obtidos pelo nosso programa.
                </p>

                <figure>
                    <img src="Images\img3post2alex.png" alt="Filtro GTFS para carreiras específicas" style="display: block; margin: auto;" />
                    <figcaption>FILTRO GTFS PARA CARREIRAS ESPECÍFICAS</figcaption>
                </figure>

                <h3>Resultados finais</h3>
                <p>
                    Conseguimos assim obter um sistema autónomo que, em tempo real, deteta, lê, corrige e envia para o exterior via áudio, toda a informação sobre os autocarros, facilitando assim o acesso a estes transportes públicos por parte de pessoas invisuais ou com baixa visão.
                </p>

                <figure>
                    <img src="Images\img4post2alex.jpg" alt="Exemplo de output final" style="display: block; margin: auto;"/>
                    <figcaption>EXEMPLO DE OUTPUT</figcaption>
                </figure>
                </article>
            <a href="blogposts.html">← Voltar ao Blog</a>
        </article>
    </main>

    <script>
        // Theme switcher JavaScript
        const themeToggle = document.getElementById('theme-switch');
        const prefersDarkScheme = window.matchMedia('(prefers-color-scheme: dark)');

        // Function to set theme
        function setTheme(theme) {
        document.documentElement.setAttribute('data-theme', theme);
        localStorage.setItem('theme', theme);
        }

        // Check for saved theme preference or use the system preference
        const savedTheme = localStorage.getItem('theme');
        if (savedTheme) {
        setTheme(savedTheme);
        } else if (prefersDarkScheme.matches) {
          setTheme('dark');
        }

        // Add click event to toggle button
        themeToggle.addEventListener('click', () => {
        const currentTheme = document.documentElement.getAttribute('data-theme') || 'light';
        const newTheme = currentTheme === 'light' ? 'dark' : 'light';
        setTheme(newTheme);
        });
    </script>
    
</body>
</html>